{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triples = pd.read_csv(\n",
    "    '../../data/processed/reference_model_f/reference_model_f.txt', header=None, sep=\"\\t\"\n",
    ")\n",
    "\n",
    "df_triples = pd.DataFrame(\n",
    "    df_triples[0].str.split(\"|\", 4).tolist(),\n",
    "    columns=[\"status\", \"article_id\", \"e1\", \"r\", \"e2\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_triples = df_triples.groupby('article_id').head(10).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stops(word):\n",
    "    if word.lower() in set(set(stopwords.words('english'))):\n",
    "        return ''\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "df_triples[\"l1\"] = (\n",
    "    df_triples[\"e1\"]\n",
    "    .apply(lambda x: extract_entities(x))\n",
    "    .apply(lemmatizer.lemmatize)\n",
    "    .apply(lambda x: x.lower().strip())\n",
    "    .apply(remove_stops)\n",
    "    .apply(lambda x: re.sub(\"[^\\s'_A-Za-z]\", \"\", x))\n",
    "    .apply(lambda x: x.lstrip().rstrip())\n",
    ")\n",
    "df_triples[\"l2\"] = (\n",
    "    df_triples[\"e2\"]\n",
    "    .apply(lambda x: extract_entities(x))\n",
    "    .apply(lemmatizer.lemmatize)\n",
    "    .apply(lambda x: x.lower().strip())\n",
    "    .apply(remove_stops)\n",
    "    .apply(lambda x: re.sub(\"[^\\s'_A-Za-z]\", \"\", x))\n",
    "    .apply(lambda x: x.lstrip().rstrip())\n",
    ")\n",
    "df_triples[\"rel\"] = (\n",
    "    df_triples[\"r\"]\n",
    "    .apply(lemmatizer.lemmatize)\n",
    "    .apply(lambda x: x.lower().strip())\n",
    "    .apply(remove_stops)\n",
    "    .apply(lambda x: re.sub(\"[^\\s'_A-Za-z]\", \"\", x))\n",
    "    .apply(lambda x: x.lstrip().rstrip())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_entities = pd.concat([df_triples[\"l1\"], df_triples[\"l2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_entities = pd.Series(total_entities.unique())\n",
    "\n",
    "d = {\n",
    "    k: v for k, v in zip(unique_entities, [i for i in range(len(unique_entities))])\n",
    "}\n",
    "\n",
    "d_sorted = sorted(d.items(), key=lambda kv: kv[1])\n",
    "\n",
    "total_relations = pd.Series(df_triples[\"rel\"])\n",
    "rc = Counter(total_relations)\n",
    "unr = Counter(el for el in rc.elements() if rc[el] > 1)\n",
    "unique_relations = pd.Series(list(unr.keys()))\n",
    "\n",
    "r = {\n",
    "    k: v\n",
    "    for k, v in zip(\n",
    "        unique_relations,\n",
    "        [i for i in range(len(unique_relations))],\n",
    "    )\n",
    "}\n",
    "\n",
    "r_sorted = sorted(r.items(), key=lambda kv: kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Counter(total_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "un = Counter(el for el in a.elements() if a[el] > 1 and el != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    res = []\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text))):\n",
    "        if hasattr(chunk, 'label') and chunk.label() == 'PERSON':\n",
    "            res.append((' '.join(c[0] for c in chunk.leaves())))\n",
    "        else:\n",
    "            pass\n",
    "    if len(res) == 0:\n",
    "        return text\n",
    "    else\n",
    "        return res[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON\n"
     ]
    }
   ],
   "source": [
    "for i in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize('i am James Kemp'))):\n",
    "    try:\n",
    "        print(i.label())\n",
    "        print(' '.join(c[0] for c in i.label.leaves()))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-396-719d1d0a1aed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'political president'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-394-262141d5164d>\u001b[0m in \u001b[0;36mextract_entities\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mperson_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mperson_count\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'PERSON'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mperson_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "extract_entities('political president')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is in', 1792),\n",
       " ('holds', 527),\n",
       " ('is with', 492),\n",
       " ('said on', 245),\n",
       " ('said in', 238),\n",
       " ('are having', 224),\n",
       " ('register', 164),\n",
       " ('told', 156),\n",
       " ('is victim of', 144),\n",
       " ('showed', 136),\n",
       " ('says', 131),\n",
       " ('released', 126),\n",
       " ('has dismissed as', 126),\n",
       " ('has confirmed', 126),\n",
       " ('handing democrats', 125),\n",
       " ('democrats', 125),\n",
       " ('boost of', 125),\n",
       " ('leads', 120),\n",
       " ('have launched', 118),\n",
       " ('held', 116),\n",
       " ('hand over', 115),\n",
       " ('defeated rival hillary hillary clinton according to', 112),\n",
       " ('framed', 108),\n",
       " ('took', 105),\n",
       " ('could gain', 104),\n",
       " ('threepoint lead in', 96),\n",
       " ('lead in', 96),\n",
       " ('drew', 96),\n",
       " ('announced', 94),\n",
       " ('make', 93),\n",
       " ('have shown', 84),\n",
       " ('made', 82),\n",
       " ('looking to', 82),\n",
       " ('said', 81),\n",
       " ('would', 80),\n",
       " ('led republican donald republican donald trump by', 80),\n",
       " ('leads republican donald republican donald trump by', 80),\n",
       " ('struggled according to', 80),\n",
       " ('called', 79),\n",
       " ('seeking', 76),\n",
       " ('opposes', 75),\n",
       " ('take', 74),\n",
       " ('shows', 73),\n",
       " ('supports', 73),\n",
       " ('are involved as', 72),\n",
       " ('become', 71),\n",
       " ('discuss', 70),\n",
       " ('see', 70),\n",
       " ('call cnbc for', 68),\n",
       " ('raise', 66)]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'us' in list(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['october',\n",
       " 'donald trump',\n",
       " 'hillary',\n",
       " 'syria',\n",
       " 'kevin shipp',\n",
       " 'myanmar',\n",
       " 'november',\n",
       " 'people',\n",
       " 'clinton',\n",
       " 'prison planetcom october',\n",
       " 'obama',\n",
       " 'dr duke',\n",
       " 'yemeni army forces',\n",
       " 'americans',\n",
       " 'fbi',\n",
       " 'russia',\n",
       " 'isis']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
